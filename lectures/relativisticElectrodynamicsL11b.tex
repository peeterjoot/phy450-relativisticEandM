%
% Copyright Â© 2012 Peeter Joot.  All Rights Reserved.
% Licenced as described in the file LICENSE under the root directory of this GIT repository.
%
\section{Four vector invariants}
\index{four vector}
\index{invariant}

For three vectors \(\BA\) and \(\BB\) invariants are

\begin{equation}\label{eqn:relativisticElectrodynamicsL11:510}
\BA \cdot \BB = A^\alpha B_\alpha
\end{equation}

For four vectors \(A^i\) and \(B^i\) invariants are

\begin{equation}\label{eqn:relativisticElectrodynamicsL11:530}
A^i B_i = A^i g_{i j} B^j
\end{equation}

For \(F_{i j}\) what are the invariants?  One invariant is

\begin{equation}\label{eqn:relativisticElectrodynamicsL11:550}
g^{i j} F_{i j} = 0,
\end{equation}

but this is not interesting since it is uniformly zero (product of symmetric and antisymmetric).

The two invariants are

\begin{equation}\label{eqn:relativisticElectrodynamicsL11:570}
F_{i j}F^{i j}
\end{equation}

and

\begin{equation}\label{eqn:relativisticElectrodynamicsL11:590}
\epsilon^{i j k l} F_{i j}F_{k l}
\end{equation}

where
\begin{equation}\label{eqn:relativisticElectrodynamicsL11:610}
\epsilon^{i j k l} =
\left\{
\begin{array}{l l}
0 & \quad \mbox{if any two indices coincide} \\
1 & \quad \mbox{for even permutations of \(i j k l=0123\) } \\
-1 & \quad \mbox{for odd permutations of \(i j k l=0123\) } \\
\end{array}
\right.
\end{equation}

We can show (homework) that

\begin{equation}\label{eqn:relativisticElectrodynamicsL11:630}
F_{i j}F^{i j} \sim \BE^2 - \BB^2
\end{equation}

\begin{equation}\label{eqn:relativisticElectrodynamicsL11:650}
\epsilon^{i j k l} F_{i j}F_{k l} \sim \BE \cdot \BB
\end{equation}

This first invariant serves as the action density for the Maxwell field equations.

There is some useful properties of these invariants.  One is that if the fields are perpendicular in one frame, then will be in any other.

From the first, note that if \(\Abs{\BE} > \Abs{\BB}\), the invariant is positive, and must be positive in all frames, or if \(\Abs{\BE} < \Abs{\BB}\), the invariant is negative, and must be negative in all frames.  Because of this if \(\Abs{\BE} > \Abs{\BB}\) in one frame, we can transform to a frame with only \(\BE'\) component, solve that, and then transform back.  Similarly if \(\Abs{\BE} < \Abs{\BB}\) in one frame, we can transform to a frame with only \(\BB'\) component, solve that, and then transform back.

\section{The first half of Maxwell's equations}
\index{Maxwell's equations}

\paragraph{Claim: } The source free portions of Maxwell's equations are a consequence of the definition of the field tensor alone.

Given
\begin{equation}\label{eqn:relativisticElectrodynamicsL11:670}
F_{i j} = \partial_i A_j - \partial_j A_i,
\end{equation}

where
\begin{equation}\label{eqn:relativisticElectrodynamicsL11:690}
\partial_i = \PD{x^i}{}
\end{equation}

This alone implies half of Maxwell's equations.  To show this we consider

\begin{equation}\label{eqn:relativisticElectrodynamicsL11:710}
\epsilon^{m k i j} \partial_k F_{i j} = 0.
\end{equation}

This is the Bianchi identity.  To demonstrate this identity, we will have to swap indices, employ derivative commutation, and then swap indices once more

\begin{equation}\label{eqn:relativisticElectrodynamicsL11b:1380}
\begin{aligned}
\epsilon^{m k i j} \partial_k F_{i j}
&= \epsilon^{m k i j} \partial_k (\partial_i A_j - \partial_j A_i) \\
&= 2 \epsilon^{m k i j} \partial_k \partial_i A_j \\
&= 2 \epsilon^{m k i j} \inv{2} \left( \partial_k \partial_i A_j + \partial_i \partial_k A_j \right) \\
&=
\epsilon^{m k i j} \partial_k \partial_i A_j
\epsilon^{m i k j} \partial_k \partial_i A_j  \\
&=
(\epsilon^{m k i j} - \epsilon^{m k i j}) \partial_k \partial_i A_j \\
&= 0. \qedmarker
\end{aligned}
\end{equation}

This is the 4D analogue of

\begin{equation}\label{eqn:relativisticElectrodynamicsL11:790}
\spacegrad \cross (\spacegrad f) = 0
\end{equation}

i.e.

\begin{equation}\label{eqn:relativisticElectrodynamicsL11:810}
\epsilon^{\alpha\beta\gamma} \partial_\beta \partial_\gamma f = 0
\end{equation}

Let us do this explicitly, starting with

\begin{equation}\label{eqn:relativisticElectrodynamicsL11:370b}
\Norm{ F_{i j} } =
\begin{bmatrix}
0 & E_x & E_y & E_z \\
-E_x & 0 & -B_z & B_y \\
-E_y & B_z & 0 & -B_x \\
-E_z & -B_y & B_x & 0.
\end{bmatrix}
\end{equation}

For the \(m= 0\) case we have

\begin{equation}\label{eqn:relativisticElectrodynamicsL11b:1400}
\begin{aligned}
\epsilon^{0 k i j} \partial_k F_{i j}
&=
\epsilon^{\alpha \beta \gamma} \partial_\alpha F_{\beta \gamma} \\
&=
\epsilon^{\alpha \beta \gamma} \partial_\alpha (-\epsilon_{\beta \gamma \delta} B_\delta) \\
&=
-\epsilon^{\alpha \beta \gamma} \epsilon_{\delta \beta \gamma }
\partial_\alpha B_\delta \\
&=
- 2 {\delta^\alpha}_\delta \partial_\alpha B_\delta \\
&=
- 2 \partial_\alpha B_\alpha
\end{aligned}
\end{equation}

We must then have

\begin{equation}\label{eqn:relativisticElectrodynamicsL11:830}
\partial_\alpha B_\alpha = 0.
\end{equation}

This is just Gauss's law for magnetism

\begin{equation}\label{eqn:relativisticElectrodynamicsL11:850}
\spacegrad \cdot \BB = 0.
\end{equation}

Let us do the spatial portion, for which we have three equations, one for each \(\alpha\) of

\begin{equation}\label{eqn:relativisticElectrodynamicsL11b:1420}
\begin{aligned}
\epsilon^{\alpha j k l} \partial_j F_{k l}
&=
\epsilon^{\alpha 0 \beta \gamma} \partial_0 F_{\beta \gamma}
+\epsilon^{\alpha 0 \gamma \beta} \partial_0 F_{\gamma \beta}
+\epsilon^{\alpha \beta 0 \gamma} \partial_\beta F_{0 \gamma} \\
&\qquad +\epsilon^{\alpha \beta \gamma 0} \partial_\beta F_{\gamma 0}
+\epsilon^{\alpha \gamma 0 \beta} \partial_\gamma F_{0 \beta}
+\epsilon^{\alpha \gamma \beta 0} \partial_\gamma F_{\beta 0} \\
&=
2 \left(
\epsilon^{\alpha 0 \beta \gamma} \partial_0 F_{\beta \gamma}
+\epsilon^{\alpha \beta 0 \gamma} \partial_\beta F_{0 \gamma}
+\epsilon^{\alpha \gamma 0 \beta} \partial_\gamma F_{0 \beta}
\right) \\
&=
2 \epsilon^{0 \alpha \beta \gamma} \left(
-\partial_0 F_{\beta \gamma}
+\partial_\beta F_{0 \gamma}
- \partial_\gamma F_{0 \beta}
\right)
\end{aligned}
\end{equation}

This implies

\begin{equation}\label{eqn:relativisticElectrodynamicsL11:1320}
0 =
-\partial_0 F_{\beta \gamma}
+\partial_\beta F_{0 \gamma}
- \partial_\gamma F_{0 \beta}
\end{equation}

Referring back to the previous expansions of \eqnref{eqn:relativisticElectrodynamicsL11:71} and \eqnref{eqn:relativisticElectrodynamicsL11:170}, we have

%F_{\beta\gamma} = - \epsilon_{\beta\gamma\mu} B_\mu.
%F_{0\alpha} = E_\alpha
\begin{equation}\label{eqn:relativisticElectrodynamicsL11:1340}
0 =
\partial_0 \epsilon_{\beta\gamma\mu} B_\mu
+\partial_\beta E_\gamma
- \partial_\gamma E_{\beta},
\end{equation}

or

\begin{equation}\label{eqn:relativisticElectrodynamicsL11:1360}
\inv{c} \PD{t}{B_\alpha} + (\spacegrad \cross \BE)_\alpha = 0.
\end{equation}

These are just the components of the Faraday's law

\begin{equation}\label{eqn:relativisticElectrodynamicsL11:930}
0 = \inv{c} \PD{t}{\BB} + \spacegrad \cross \BE.
\end{equation}

\section{Appendix. Some additional index gymnastics}

\paragraph{Transposition of mixed index tensor}

Is the transpose of a mixed index object just a substitution of the free indices?  This was not obvious to me that it would be the case, especially since I had made an error in some index gymnastics that had me temporarily convinced differently.  However, working some examples clears the fog.  For example let us take the transpose of \eqnref{eqn:relativisticElectrodynamicsL11:470}.

\begin{equation}\label{eqn:relativisticElectrodynamicsL11b:1440}
\begin{aligned}
\Norm{ {\delta^i}_j }^\T
&=
\Norm{ O^{a i} O_{a j} }^\T \\
&=
\left( \Norm{ O^{j i} } \Norm{ O_{i j} } \right)^\T \\
&=
\Norm{ O_{i j} }^\T
\Norm{ O^{j i} }^\T  \\
&=
\Norm{ O_{j i} }
\Norm{ O^{i j} } \\
&=
\Norm{ O_{a i} O^{a j} } \\
\end{aligned}
\end{equation}

If the transpose of a mixed index tensor just swapped the indices we would have

\begin{equation}\label{eqn:relativisticElectrodynamicsL11:1060}
\Norm{ {\delta^i}_j }^\T = \Norm{ O_{a i} O^{a j} }
\end{equation}

From this it does appear that all we have to do is switch the indices and we will write
\begin{equation}\label{eqn:relativisticElectrodynamicsL11:1060b}
{\delta^j}_i = O_{a i} O^{a j}
\end{equation}

%It would be easy to brush aside this bit of slight of hand here in the transposition with the positioning of the indices?
%With all this index gymnastics, even the transposition operation appears to be something that we have to treat carefully.
We can consider a more general operation

\begin{equation}\label{eqn:relativisticElectrodynamicsL11b:1460}
\begin{aligned}
\Norm{{A^i}_j}^\T
&=
\Norm{ A^{i m} g_{m j} }^\T \\
&=
\Norm{ g_{i j} }^\T
\Norm{ A^{i j} }^\T
 \\
&=
\Norm{ g_{i j} }
\Norm{ A^{j i} }
 \\
&=
\Norm{ g_{i m} A^{j m} }
 \\
&=
\Norm{ {A^{j}}_i }
\end{aligned}
\end{equation}

So we see that we do just have to swap indices.

%So, provided
%
%\begin{equation}\label{eqn:relativisticElectrodynamicsL11:980}
%\Norm{A^{i j}}^\T = \Norm{A^{j i}},
%\end{equation}
%
%which we also assumed earlier as well, we have
%
%\begin{equation}\label{eqn:relativisticElectrodynamicsL11:1001}
%\Norm{{A^i}_j}^\T =
%\Norm{ {A_{i}}^j }
%\end{equation}
%
%The transposition operation on this mixed index delta function lowers and raises the indices as opposed to just swapping them, as we are used to in plain old Euclidean \R{N} matrix operations.

\paragraph{Transposition of lower index tensor}

We have saw above that we had

\begin{equation}\label{eqn:relativisticElectrodynamicsL11:1022}
\begin{aligned}
\Norm{ {A^{i}}_j }^\T &= \Norm{ {A_{j}}^i } \\
\Norm{ {A_{i}}^j }^\T &= \Norm{ {A^{j}}_i }
\end{aligned}
\end{equation}

which followed by careful treatment of the transposition in terms of \(A^{i j}\) for which we defined a transpose operation.  We assumed as well that

\begin{equation}\label{eqn:relativisticElectrodynamicsL11:1042}
\Norm{ A_{i j} }^\T = \Norm{ A_{j i} }.
\end{equation}

However, this does not have to be assumed, provided that \(g^{i j} = g_{i j}\), and \((AB)^\T = B^\T A^\T\).  We see this by expanding this transposition in products of \(A^{i j}\) and \(\hat{G}\)

\begin{equation}\label{eqn:relativisticElectrodynamicsL11b:1480}
\begin{aligned}
\Norm{ A_{i j} }^\T
&= \left( \Norm{g_{i j}} \Norm{ A^{i j} } \Norm{g_{i j}} \right)^\T \\
&= \left( \Norm{g^{i j}} \Norm{ A^{i j} } \Norm{g^{i j}} \right)^\T \\
&= \Norm{g^{i j}}^\T \Norm{ A^{i j}}^\T \Norm{g^{i j}}^\T \\
&= \Norm{g^{i j}} \Norm{ A^{j i}} \Norm{g^{i j}} \\
&= \Norm{g_{i j}} \Norm{ A^{i j}} \Norm{g_{i j}} \\
&= \Norm{ A_{j i}}
\end{aligned}
\end{equation}

It would be worthwhile to go through all of this index manipulation stuff and lay it out in a structured axiomatic form.  What is the minimal set of assumptions, and how does all of this generalize to non-diagonal metric tensors (even in Euclidean spaces).

\paragraph{Translating the index expression of identity from Lorentz products to matrix form}

A verification that the matrix expression \eqnref{eqn:relativisticElectrodynamicsL11:471}, matches the index expression \eqnref{eqn:relativisticElectrodynamicsL11:470} as claimed is worthwhile.  It would be easy to guess something similar like \(\hat{O}^\T \hat{G} \hat{O} \hat{G}\) is instead the matrix representation.  That was in fact my first erroneous attempt to form the matrix equivalent, but is the transpose of \eqnref{eqn:relativisticElectrodynamicsL11:471}.  Either way you get an identity, but the indices did not match.

Since we have \(g^{i j} = g_{i j}\) which do we pick to do this verification?  This appears to be dictated by requirements to match lower and upper indices on the summed over index.  This is probably clearest by example, so let us expand the products on the LHS explicitly

\begin{equation}\label{eqn:relativisticElectrodynamicsL11b:1500}
\begin{aligned}
\Norm{ g^{i j} }
\Norm{ {O^{i}}_j } ^\T
\Norm{ g_{i j} }
\Norm{ {O^{i}}_j }
&=
\left( \Norm{ {O^{i}}_j }
\Norm{ g^{i j} } \right) ^\T
\Norm{ g_{i j} }
\Norm{ {O^{i}}_j }  \\
&=
\left( \Norm{ {O^{i}}_k g^{k j} } \right) ^\T
\Norm{ g_{i m} {O^{m}}_j }  \\
&=
\Norm{ O^{i j} } ^\T
\Norm{ O_{i j} }  \\
&=
\Norm{ O^{j i} }
\Norm{ O_{i j} }  \\
&=
\Norm{ O^{k i} O_{k j} }  \\
\end{aligned}
\end{equation}

This matches the \(\Norm{{\delta^i}_j}\) that we have on the RHS, and all is well.

%
% Copyright © 2012 Peeter Joot.  All Rights Reserved.
% Licenced as described in the file LICENSE under the root directory of this GIT repository.
%

%\chapter{Problem Set 3}
\label{chap:relElectroDynProblemSet3}
%\blogpage{http://sites.google.com/site/peeterjoot/math2011/relElectroDynProblemSet3.pdf}
%\date{Feb 15, 2011}

\makeproblem{Fun with \( \epsilon_{\alpha\beta\gamma}, \epsilon^{ijkl}, F_{ij} \), and the duality of Maxwell's equations in vacuum}{pr:relElectroDynProblemSet3:1}{

\makesubproblem{rank 3 spatial antisymmetric tensor identities}{pr:relElectroDynProblemSet3:1a}

Prove that

\begin{equation}\label{eqn:relElectroDynProblemSet3:10}
\epsilon_{\alpha \beta \gamma}
\epsilon_{\mu \nu \gamma}
=
\delta_{\alpha\mu} \delta_{\beta\nu}
-\delta_{\alpha\nu} \delta_{\beta\mu}
\end{equation}

and use it to find the familiar relation for

\begin{equation}\label{eqn:relElectroDynProblemSet3:30}
(\BA \cross \BB) \cdot (\BC \cross \BD)
\end{equation}

Also show that

\begin{equation}\label{eqn:relElectroDynProblemSet3:50}
\epsilon_{\alpha \beta \gamma}
\epsilon_{\mu \beta \gamma}
=
2 \delta_{\alpha\mu}.
\end{equation}

(Einstein summation implied all throughout this problem).

\makesubproblem{Determinant of three by three matrix}{pr:relElectroDynProblemSet3:1b}

Prove that for any \(3 \times 3\) matrix \(\Norm{A_{\alpha\beta}}\): \(\epsilon_{\mu\nu\lambda} A_{\alpha \mu} A_{\beta\nu} A_{\gamma\lambda} = \epsilon_{\alpha \beta \gamma} \Det A\) and that \(\epsilon_{\alpha\beta\gamma} \epsilon_{\mu\nu\lambda} A_{\alpha \mu} A_{\beta\nu} A_{\gamma\lambda} = 6 \Det A\).

\makesubproblem{Rotational invariance of 3D antisymmetric tensor}{pr:relElectroDynProblemSet3:1c}

Use the previous results to show that \(\epsilon_{\mu\nu\lambda}\) is invariant under rotations.

\makesubproblem{Rotational invariance of 4D antisymmetric tensor}{pr:relElectroDynProblemSet3:1d}

Use the previous results to show that \(\epsilon_{i j k l}\) is invariant under Lorentz transformations.

\makesubproblem{Sum of contracting symmetric and antisymmetric rank 2 tensors}{pr:relElectroDynProblemSet3:1e}

Show that \(A^{ij} B_{ij} = 0\) if \(A\) is symmetric and \(B\) is antisymmetric.

\makesubproblem{Characteristic equation for the electromagnetic strength tensor}{pr:relElectroDynProblemSet3:1f}

Show that \(P(\lambda) = \Det \Norm{F_{i j} - \lambda g_{i j}}\) is invariant under Lorentz transformations.  Consider the polynomial of \(P(\lambda)\), also called the characteristic polynomial of the matrix \(\Norm{F_{i j}}\).  Find the coefficients of the expansion of \(P(\lambda)\) in powers of \(\lambda\) in terms of the components of \(\Norm{F_{i j}}\).  Use the result to argue that \(\BE \cdot \BB\) and \(\BE^2 - \BB^2\) are Lorentz invariant.

\makesubproblem{Show that the pseudoscalar invariant has only boundary effects}{pr:relElectroDynProblemSet3:1g}

Use integration by parts to show that \(\int d^4 x \epsilon^{i j k l} F_{ i j } F_{ k l }\) only depends on the values of \(A^i(x)\) at the ``boundary'' of spacetime (e.g. the ``surface'' depicted on page 105 of the notes) and hence does not affect the equations of motion for the electromagnetic field.
\makesubproblem{Electromagnetic duality transformations}{pr:relElectroDynProblemSet3:1h}

Show that the Maxwell equations in vacuum are invariant under the transformation: \(F_{i j} \rightarrow \tilde{F}_{i j}\), where \(\tilde{F}_{i j} = \inv{2} \epsilon_{i j k l} F^{k l}\) is the dual electromagnetic stress tensor.  Replacing \(F\) with \(\tilde{F}\) is known as ``electric-magnetic duality''.  Explain this name by considering the transformation in terms of \(\BE\) and \(\BB\).  Are the Maxwell equations with sources invariant under electric-magnetic duality transformations?

} % makeproblem

\makeanswer{pr:relElectroDynProblemSet3:1}{
\makeSubAnswer{}{pr:relElectroDynProblemSet3:1a}

We can explicitly expand the (implied) sum over indices \(\gamma\).  This is

\begin{equation}\label{eqn:relElectroDynProblemSet3:70}
\epsilon_{\alpha \beta \gamma}
\epsilon_{\mu \nu \gamma}
=
\epsilon_{\alpha \beta 1} \epsilon_{\mu \nu 1}
+\epsilon_{\alpha \beta 2} \epsilon_{\mu \nu 2}
+\epsilon_{\alpha \beta 3} \epsilon_{\mu \nu 3}
\end{equation}

For any \(\alpha \ne \beta\) only one term is non-zero.  For example with \(\alpha,\beta = 2,3\), we have just a contribution from the \(\gamma = 1\) part of the sum

\begin{equation}\label{eqn:relElectroDynProblemSet3:90}
\epsilon_{2 3 1} \epsilon_{\mu \nu 1}.
\end{equation}

The value of this for \((\mu,\nu) = (\alpha,\beta)\) is

\begin{equation}\label{eqn:relElectroDynProblemSet3:110}
(\epsilon_{2 3 1})^2
\end{equation}

whereas for \((\mu,\nu) = (\beta,\alpha)\) we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:130}
-(\epsilon_{2 3 1})^2
\end{equation}

Our sum has value one when \((\alpha, \beta)\) matches \((\mu, \nu)\), and value minus one for when \((\mu, \nu)\) are permuted.  We can summarize this, by saying that when \(\alpha \ne \beta\) we have

\boxedEquation{eqn:relElectroDynProblemSet3:150}{
\epsilon_{\alpha \beta \gamma}
\epsilon_{\mu \nu \gamma}
=
\delta_{\alpha\mu} \delta_{\beta\nu}
-\delta_{\alpha\nu} \delta_{\beta\mu}.
}

However, observe that when \(\alpha = \beta\) the RHS is

\begin{equation}\label{eqn:relElectroDynProblemSet3:170}
\delta_{\alpha\mu} \delta_{\alpha\nu}
-\delta_{\alpha\nu} \delta_{\alpha\mu} = 0,
\end{equation}

as desired, so this form works in general without any \(\alpha \ne \beta\) qualifier, completing this part of the problem.

\begin{equation}\label{eqn:relElectroDynProblemSet3:2140}
\begin{aligned}
(\BA \cross \BB) \cdot (\BC \cross \BD)
&=
(\epsilon_{\alpha \beta \gamma} \Be^\alpha A^\beta B^\gamma ) \cdot
(\epsilon_{\mu \nu \sigma} \Be^\mu C^\nu D^\sigma ) \\
&=
\epsilon_{\alpha \beta \gamma} A^\beta B^\gamma
\epsilon_{\alpha \nu \sigma} C^\nu D^\sigma \\
&=
(
\delta_{\beta \nu} \delta_{\gamma\sigma}
-\delta_{\beta \sigma} \delta_{\gamma\nu} )
A^\beta B^\gamma
C^\nu D^\sigma \\
&=
A^\nu B^\sigma
C^\nu D^\sigma
-A^\sigma B^\nu
C^\nu D^\sigma.
\end{aligned}
\end{equation}

This gives us
\boxedEquation{eqn:relElectroDynProblemSet3:190}{
(\BA \cross \BB) \cdot (\BC \cross \BD)
=
(\BA \cdot \BC)
(\BB \cdot \BD)
-
(\BA \cdot \BD)
(\BB \cdot \BC).
}

We have one more identity to deal with.

\begin{equation}\label{eqn:relElectroDynProblemSet3:210}
\epsilon_{\alpha \beta \gamma}
\epsilon_{\mu \beta \gamma}
\end{equation}

We can expand out this (implied) sum slow and dumb as well

\begin{equation}\label{eqn:relElectroDynProblemSet3:2160}
\begin{aligned}
\epsilon_{\alpha \beta \gamma}
\epsilon_{\mu \beta \gamma}
&=
\epsilon_{\alpha 1 2} \epsilon_{\mu 1 2}
+\epsilon_{\alpha 2 1} \epsilon_{\mu 2 1} \\
&+\epsilon_{\alpha 1 3} \epsilon_{\mu 1 3}
+\epsilon_{\alpha 3 1} \epsilon_{\mu 3 1} \\
&+\epsilon_{\alpha 2 3} \epsilon_{\mu 2 3}
+\epsilon_{\alpha 3 2} \epsilon_{\mu 3 2} \\
&=
2 \epsilon_{\alpha 1 2} \epsilon_{\mu 1 2}
+ 2 \epsilon_{\alpha 1 3} \epsilon_{\mu 1 3}
+ 2 \epsilon_{\alpha 2 3} \epsilon_{\mu 2 3}
\end{aligned}
\end{equation}

Now, observe that for any \(\alpha \in (1,2,3)\) only one term of this sum is picked up.  For example, with no loss of generality, pick \(\alpha = 1\).  We are left with only

\begin{equation}\label{eqn:relElectroDynProblemSet3:230}
2 \epsilon_{1 2 3} \epsilon_{\mu 2 3}
\end{equation}

This has the value
\begin{equation}\label{eqn:relElectroDynProblemSet3:250}
2 (\epsilon_{1 2 3})^2 = 2
\end{equation}

when \(\mu = \alpha\) and is zero otherwise.  We can therefore summarize the evaluation of this sum as

\boxedEquation{eqn:relElectroDynProblemSet3:270}{
\epsilon_{\alpha \beta \gamma}
\epsilon_{\mu \beta \gamma}
=  2\delta_{\alpha\mu},
}

completing this problem.

\makeSubAnswer{}{pr:relElectroDynProblemSet3:1b}

In class Simon showed us how the first identity can be arrived at using the triple product \(\Ba \cdot (\Bb \cross \Bc) = \Det(\Ba \Bb \Bc)\).  It occurred to me later that I had seen the identity to be proven in the context of Geometric Algebra, but hhad not recognized it in this tensor form.  Basically, a wedge product can be expanded in sums of determinants, and when the dimension of the space is the same as the vector, we have a pseudoscalar times the determinant of the components.

For example, in \R{2}, let us take the wedge product of a pair of vectors.  As preparation for the relativistic \R{4} case We will not require an orthonormal basis, but express the vector in terms of a reciprocal frame and the associated components

\begin{equation}\label{eqn:relElectroDynProblemSet3:290}
a = a^i e_i = a_j e^j
\end{equation}

where
\begin{equation}\label{eqn:relElectroDynProblemSet3:310}
e^i \cdot e_j = {\delta^i}_j.
\end{equation}

When we get to the relativistic case, we can pick (but do not have to) the standard basis

\begin{equation}\label{eqn:relElectroDynProblemSet3:330}
\begin{aligned}
e_0 &= (1, 0, 0, 0) \\
e_1 &= (0, 1, 0, 0) \\
e_2 &= (0, 0, 1, 0) \\
e_3 &= (0, 0, 0, 1),
\end{aligned}
\end{equation}

for which our reciprocal frame is implicitly defined by the metric
\begin{equation}\label{eqn:relElectroDynProblemSet3:350}
\begin{aligned}
e^0 &= (1, 0, 0, 0) \\
e^1 &= (0, -1, 0, 0) \\
e^2 &= (0, 0, -1, 0) \\
e^3 &= (0, 0, 0, -1).
\end{aligned}
\end{equation}

Anyways.  Back to the problem.  Let us examine the \R{2} case.  Our wedge product in coordinates is

\begin{equation}\label{eqn:relElectroDynProblemSet3:370}
a \wedge b
=
a^i b^j (e_i \wedge e_j)
\end{equation}

Since there are only two basis vectors we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:390}
a \wedge b
=
(a^1 b^2 - a^2 b^1) e_1 \wedge e_2 = \Det \Norm{a^i b^j} (e_1 \wedge e_2).
\end{equation}

Our wedge product is a product of the determinant of the vector coordinates, times the \R{2} pseudoscalar \(e_1 \wedge e_2\).

This does not look quite like the \R{3} relation that we want to prove, which had an antisymmetric tensor factor for the determinant.  Observe that we get the determinant by picking off the \(e_1 \wedge e_2\) component of the bivector result (the only component in this case), and we can do that by dotting with \(e^2 \cdot e^1\).  To get an antisymmetric tensor times the determinant, we have only to dot with a different pseudoscalar (one that differs by a possible sign due to permutation of the indices).  That is

\begin{equation}\label{eqn:relElectroDynProblemSet3:2180}
\begin{aligned}
(e^t \wedge e^s) \cdot (a \wedge b)
&=
a^i b^j (e^t \wedge e^s) \cdot (e_i \wedge e_j) \\
&=
a^i b^j
\left( {\delta^{s}}_i {\delta^{t}}_j
-{\delta^{t}}_i {\delta^{s}}_j  \right) \\
&=
a^i b^j
{\delta^{[t}}_j {\delta^{s]}}_i \\
&=
a^i b^j
{\delta^{t}}_{[j} {\delta^{s}}_{i]} \\
&=
a^{[i} b^{j]}
{\delta^{t}}_{j} {\delta^{s}}_{i} \\
&=
a^{[s} b^{t]}
\end{aligned}
\end{equation}

Now, if we write \(a^i = A^{1 i}\) and \(b^j = A^{2 j}\) we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:410}
(e^t \wedge e^s) \cdot (a \wedge b)
=
A^{1 s} A^{2 t} -A^{1 t} A^{2 s}
\end{equation}

We can write this in two different ways.  One of which is

\begin{equation}\label{eqn:relElectroDynProblemSet3:430}
A^{1 s} A^{2 t} -A^{1 t} A^{2 s} =
\epsilon^{s t} \Det \Norm{A^{ij}}
\end{equation}

and the other of which is by introducing free indices for \(1\) and \(2\), and summing antisymmetrically over these.  That is

\begin{equation}\label{eqn:relElectroDynProblemSet3:450}
A^{1 s} A^{2 t} -A^{1 t} A^{2 s}
=
A^{a s} A^{b t} \epsilon_{a b}
\end{equation}

So, we have

\boxedEquation{eqn:relElectroDynProblemSet3:470}{
A^{a s} A^{b t} \epsilon_{a b} =
A^{1 i} A^{2 j} {\delta^{[t}}_j {\delta^{s]}}_i =
\epsilon^{s t} \Det \Norm{A^{ij}},
}

This result hold regardless of the metric for the space, and does not require that we were using an orthonormal basis.  When the metric is Euclidean and we have an orthonormal basis, then all the indices can be dropped.

The \R{3} and \R{4} cases follow in exactly the same way, we just need more vectors in the wedge products.

For the \R{3} case we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:2200}
\begin{aligned}
(e^u \wedge e^t \wedge e^s) \cdot ( a \wedge b \wedge c)
&=
a^i b^j c^k
(e^u \wedge e^t \wedge e^s) \cdot (e_i \wedge e_j \wedge e_k) \\
&=
a^i b^j c^k
{\delta^{[u}}_k
{\delta^{t}}_j
{\delta^{s]}}_i \\
&=
a^{[s} b^t c^{u]}
\end{aligned}
\end{equation}

Again, with \(a^i = A^{1 i}\) and \(b^j = A^{2 j}\), and \(c^k = A^{3 k}\) we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:490}
(e^u \wedge e^t \wedge e^s) \cdot ( a \wedge b \wedge c)
=
A^{1 i} A^{2 j} A^{3 k}
{\delta^{[u}}_k
{\delta^{t}}_j
{\delta^{s]}}_i
\end{equation}

and we can choose to write this in either form, resulting in the identity

\boxedEquation{eqn:relElectroDynProblemSet3:510}{
\epsilon^{s t u} \Det \Norm{A^{ij}}
=
A^{1 i} A^{2 j} A^{3 k}
{\delta^{[u}}_k
{\delta^{t}}_j
{\delta^{s]}}_i
=
\epsilon_{a b c} A^{a s} A^{b t} A^{c u}.
}

The \R{4} case follows exactly the same way, and we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:2220}
\begin{aligned}
(e^v \wedge e^u \wedge e^t \wedge e^s) \cdot ( a \wedge b \wedge c \wedge d)
&=
a^i b^j c^k d^l
(e^v \wedge e^u \wedge e^t \wedge e^s) \cdot (e_i \wedge e_j \wedge e_k \wedge e_l) \\
&=
a^i b^j c^k d^l
{\delta^{[v}}_l
{\delta^{u}}_k
{\delta^{t}}_j
{\delta^{s]}}_i \\
&=
a^{[s} b^t c^{u} d^{v]}.
\end{aligned}
\end{equation}

This time with \(a^i = A^{0 i}\) and \(b^j = A^{1 j}\), and \(c^k = A^{2 k}\), and \(d^l = A^{3 l}\) we have

\boxedEquation{eqn:relElectroDynProblemSet3:530}{
\epsilon^{s t u v} \Det \Norm{A^{ij}}
=
A^{0 i} A^{1 j} A^{2 k} A^{3 l}
{\delta^{[v}}_l
{\delta^{u}}_k
{\delta^{t}}_j
{\delta^{s]}}_i
=
\epsilon_{a b c d} A^{a s} A^{b t} A^{c u} A^{d v}.
}

This one is almost the identity to be established later in problem 1.4.  We have only to raise and lower some indices to get that one.  Note that in the Minkowski standard basis above, because \(s, t, u, v\) must be a permutation of \(0,1,2,3\) for a non-zero result, we must have

\begin{equation}\label{eqn:relElectroDynProblemSet3:550}
\epsilon^{s t u v} = (-1)^3 (+1) \epsilon_{s t u v}.
\end{equation}

So raising and lowering the identity above gives us

\begin{equation}\label{eqn:relElectroDynProblemSet3:570}
-\epsilon_{s t u v} \Det \Norm{A_{ij}}
=
\epsilon^{a b c d} A_{a s} A_{b t} A_{c u} A_{d u}.
\end{equation}

No sign changes were required for the indices \(a, b, c, d\), since they are paired.

Until we did the raising and lowering operations here, there was no specific metric required, so our first result \eqnref{eqn:relElectroDynProblemSet3:530} is the more general one.

There is one more part to this problem, doing the antisymmetric sums over the indices \(s, t, \cdots\).  For the \R{2} case we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:2240}
\begin{aligned}
\epsilon_{s t} \epsilon_{a b} A^{a s} A^{b t}
&=
\epsilon_{s t} \epsilon^{s t} \Det \Norm{A^{ij}} \\
&=
\left(
\epsilon_{1 2} \epsilon^{1 2}
+\epsilon_{2 1} \epsilon^{2 1}
\right)
\Det \Norm{A^{ij}} \\
&=
\left(
1^2 + (-1)^2
\right)
\Det \Norm{A^{ij}}
\end{aligned}
\end{equation}

We conclude that

\boxedEquation{eqn:relElectroDynProblemSet3:600}{
\epsilon_{s t} \epsilon_{a b} A^{a s} A^{b t} = 2! \Det \Norm{A^{ij}}.
}

For the \R{3} case we have the same operation

\begin{equation}\label{eqn:relElectroDynProblemSet3:2260}
\begin{aligned}
\epsilon_{s t u} \epsilon_{a b c} A^{a s} A^{b t} A^{c u}
&=
\epsilon_{s t u} \epsilon^{s t u} \Det \Norm{A^{ij}} \\
&=
\left(
\epsilon_{1 2 3} \epsilon^{1 2 3}
+\epsilon_{1 3 2} \epsilon^{1 3 2}
+ \cdots
\right)
\Det \Norm{A^{ij}} \\
&=
(\pm 1)^2 (3!)
\Det \Norm{A^{ij}}.
\end{aligned}
\end{equation}

So we conclude
\boxedEquation{eqn:relElectroDynProblemSet3:620}{
\epsilon_{s t u} \epsilon_{a b c} A^{a s} A^{b t} A^{c u}= 3! \Det \Norm{A^{ij}}.
}

It is clear what the pattern is, and if we evaluate the sum of the antisymmetric tensor squares in \R{4} we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:2280}
\begin{aligned}
\epsilon_{s t u v} \epsilon_{s t u v}
&=
\epsilon_{0 1 2 3} \epsilon_{0 1 2 3}
+
\epsilon_{0 1 3 2} \epsilon_{0 1 3 2}
+
\epsilon_{0 2 1 3} \epsilon_{0 2 1 3}
+ \cdots \\
&= (\pm 1)^2 (4!),
\end{aligned}
\end{equation}

So, for our SR case we have
\boxedEquation{eqn:relElectroDynProblemSet3:640}{
\epsilon_{s t u v} \epsilon_{a b c d} A^{a s} A^{b t} A^{c u} A^{d v}= 4! \Det \Norm{A^{ij}}.
}

This was part of question 1.4, albeit in lower index form.  Here since all indices are matched, we have the same result without major change

\boxedEquation{eqn:relElectroDynProblemSet3:660}{
\epsilon^{s t u v} \epsilon^{a b c d} A_{a s} A_{b t} A_{c u} A_{d v}= 4! \Det \Norm{A_{ij}}.
}

The main difference is that we are now taking the determinant of a lower index tensor.

\makeSubAnswer{}{pr:relElectroDynProblemSet3:1c}

We apply transformations to coordinates (and thus indices) of the form

\begin{equation}\label{eqn:relElectroDynProblemSet3:680}
x_\mu \rightarrow O_{\mu\nu} x_\nu
\end{equation}

With our tensor transforming as its indices, we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:700}
\epsilon_{\mu\nu\lambda} \rightarrow \epsilon_{\alpha\beta\sigma} O_{\mu\alpha} O_{\nu\beta} O_{\lambda\sigma}.
\end{equation}

We have got \eqnref{eqn:relElectroDynProblemSet3:510}, which after dropping indices, because we are in a Euclidean space, we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:510b}
\epsilon_{\mu \nu \lambda} \Det \Norm{A_{ij}} = \epsilon_{\alpha \beta \sigma} A_{\alpha \mu} A_{\beta \nu} A_{\sigma \lambda}.
\end{equation}

Let \(A_{i j} = O_{j i}\), which gives us

\begin{equation}\label{eqn:relElectroDynProblemSet3:720}
\epsilon_{\mu\nu\lambda} \rightarrow \epsilon_{\mu\nu\lambda} \Det A^\T
\end{equation}

but since \(\Det O = \Det O^\T\), we have shown that \(\epsilon_{\mu\nu\lambda}\) is invariant under rotation.


\makeSubAnswer{}{pr:relElectroDynProblemSet3:1d}

This follows the same way.  We assume a transformation of coordinates of the following form

\begin{equation}\label{eqn:relElectroDynProblemSet3:740}
\begin{aligned}
(x')^i &= {O^i}_j x^j \\
(x')_i &= {O_i}^j x_j,
\end{aligned}
\end{equation}

where the determinant of \({O^i}_j = 1\) (sanity check of sign: \({O^i}_j = {\delta^i}_j\)).

Our antisymmetric tensor transforms as its coordinates individually

\begin{equation}\label{eqn:relElectroDynProblemSet3:2300}
\begin{aligned}
\epsilon_{i j k l}
&\rightarrow \epsilon_{a b c d}
{O_i}^a
{O_j}^b
{O_k}^c
{O_l}^d \\
&= \epsilon^{a b c d}
O_{i a}
O_{j b}
O_{k c}
O_{l d} \\
\end{aligned}
\end{equation}

Let \(P_{ij} = O_{ji}\), and raise and lower all the indices in \eqnref{eqn:relElectroDynProblemSet3:530b} for
\begin{equation}\label{eqn:relElectroDynProblemSet3:530b}
-\epsilon_{s t u v} \Det \Norm{P_{ij}}
=
\epsilon^{a b c d} P_{a s} P_{b t} P_{c u} P_{d v}.
\end{equation}

We have
\begin{equation}\label{eqn:relElectroDynProblemSet3:2320}
\begin{aligned}
\epsilon_{i j k l}
&= \epsilon^{a b c d}
P_{a i}
P_{a j}
P_{a k}
P_{a l} \\
&=
-\epsilon_{i j k l} \Det \Norm{P_{ij}} \\
&=
-\epsilon_{i j k l} \Det \Norm{O_{ij}} \\
&=
-\epsilon_{i j k l} \Det \Norm{g_{im} {O^m}_j } \\
&=
-\epsilon_{i j k l} (-1)(1) \\
&=
\epsilon_{i j k l}
\end{aligned}
\end{equation}

Since \(\epsilon_{i j k l} = -\epsilon^{i j k l}\) both are therefore invariant under Lorentz transformation.


\makeSubAnswer{}{pr:relElectroDynProblemSet3:1e}

We swap indices in \(B\), switch dummy indices, then swap indices in \(A\)

\begin{equation}\label{eqn:relElectroDynProblemSet3:2340}
\begin{aligned}
A^{i j} B_{i j}
&=
-A^{i j} B_{j i} \\
&=
-A^{j i} B_{i j} \\
&=
-A^{i j} B_{i j} \\
\end{aligned}
\end{equation}

Our result is the negative of itself, so must be zero.


\makeSubAnswer{}{pr:relElectroDynProblemSet3:1f}

\paragraph{The invariance of the determinant}

Let us consider how any lower index rank 2 tensor transforms.  Given a transformation of coordinates

\begin{equation}\label{eqn:relElectroDynProblemSet3:800}
\begin{aligned}
(x^i)' &= {O^i}_j x^j \\
(x_i)' &= {O_i}^j x^j ,
\end{aligned}
\end{equation}

where \(\Det \Norm{ {O^i}_j } = 1\), and \({O_i}^j = {O^m}_n g_{i m} g^{j n}\).  Let us reflect briefly on why this determinant is unit valued.  We have

\begin{equation}\label{eqn:relElectroDynProblemSet3:820}
(x^i)' (x_i)'
= {O_i}^a x^a {O^i}_b x^b = x^b x_b,
\end{equation}

which implies that the transformation product is
\begin{equation}\label{eqn:relElectroDynProblemSet3:840}
{O_i}^a {O^i}_b = {\delta^a}_b,
\end{equation}

the identity matrix.  The identity matrix has unit determinant, so we must have

\begin{equation}\label{eqn:relElectroDynProblemSet3:860}
1 = (\Det \hat{G})^2 (\Det \Norm{ {O^i}_j })^2.
\end{equation}

Since \(\Det \hat{G} = -1\) we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:880}
\Det \Norm{ {O^i}_j } = \pm 1,
\end{equation}

which is all that we can say about the determinant of this class of transformations by considering just invariance.  If we restrict the transformations of coordinates to those of the same determinant sign as the identity matrix, we rule out reflections in time or space.  This seems to be the essence of the \(SO(1,3)\) labeling.

Why dwell on this?  Well, I wanted to be clear on the conventions I had chosen, since parts of the course notes used \(\hat{O} = \Norm{O^{i j}}\), and \(X' = \hat{O} X\), and gave that matrix unit determinant.  That \(O^{i j}\) looks like it is equivalent to my \({O^i}_j\), except that the one in the course notes is loose when it comes to lower and upper indices since it gives \((x')^i = O^{i j} x^j\).

I will write

\begin{equation}\label{eqn:relElectroDynProblemSet3:900}
\hat{O} = \Norm{{O^i}_j},
\end{equation}

and require this (not \(\Norm{O^{i j}}\)) to be the matrix with unit determinant.  Having cleared the index upper and lower confusion I had trying to reconcile the class notes with the rules for index manipulation, let us now consider the Lorentz transformation of a lower index rank 2 tensor (not necessarily antisymmetric or symmetric)

We have, transforming in the same fashion as a lower index coordinate four vector (but twice, once for each index)

\begin{equation}\label{eqn:relElectroDynProblemSet3:920}
A_{i j} \rightarrow
A_{k m}
{O_i}^k
{O_j}^m.
\end{equation}

The determinant of the transformation tensor \({O_i}^j\) is

\begin{equation}\label{eqn:relElectroDynProblemSet3:940}
\Det \Norm{ {O_i}^j } =
\Det \Norm{ g^{i m} {O^m}_n g^{n j} } = (\Det \hat{G}) (1) (\Det \hat{G} ) = (-1)^2 (1) = 1.
\end{equation}

We see that the determinant of a lower index rank 2 tensor is invariant under Lorentz transformation.  This would include our characteristic polynomial \(P(\lambda)\).

\paragraph{Expanding the determinant}

Utilizing \eqnref{eqn:relElectroDynProblemSet3:660} we can now calculate the characteristic polynomial.  This is

\begin{equation}\label{eqn:relElectroDynProblemSet3:2360}
\begin{aligned}
\Det \Norm{F_{ij} - \lambda g_{ij} }
&=
\inv{4!}
\epsilon^{s t u v} \epsilon^{a b c d}
(F_{ a s } - \lambda g_{a s}) (F_{ b t } - \lambda g_{b t}) (F_{ c u } - \lambda g_{c u}) (F_{ d v } - \lambda g_{d v}) \\
&=
\inv{24}
\epsilon^{s t u v} \epsilon_{a b c d}
({F^a}_s - \lambda {g^a}_s) ({F^b}_t - \lambda {g^b}_t) ({F^c}_u - \lambda {g^c}_u) ({F^d}_v - \lambda {g^d}_v) \\
\end{aligned}
\end{equation}

However, \({g^a}_b = g_{b c} g^{a c}\), or \(\Norm{{g^a}_b} = \hat{G}^2 = I\).  This means we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:960}
{g^a}_b = {\delta^a}_b,
\end{equation}

and our determinant is reduced to

\begin{equation}\label{eqn:relElectroDynProblemSet3:961}
\begin{aligned}
P(\lambda)
&=
\inv{24}
\epsilon^{s t u v} \epsilon_{a b c d}
\Bigl({F^a}_s {F^b}_t - \lambda( {\delta^a}_s {F^b}_t + {\delta^b}_t {F^a}_s ) + \lambda^2 {\delta^a}_s {\delta^b}_t \Bigr) \\
&\times \qquad \qquad \Bigl({F^c}_u {F^d}_v - \lambda( {\delta^c}_u {F^d}_v + {\delta^d}_v {F^c}_u ) + \lambda^2 {\delta^c}_u {\delta^d}_v \Bigr)
\end{aligned}
\end{equation}

If we expand this out we have our powers of \(\lambda\) coefficients are

\begin{equation}\label{eqn:relElectroDynProblemSet3:2380}
\begin{aligned}
\lambda^0 &:
\inv{24} \epsilon^{s t u v} \epsilon_{a b c d}
{F^a}_s {F^b}_t {F^c}_u {F^d}_v
\\
\lambda^1 &:
\inv{24} \epsilon^{s t u v} \epsilon_{a b c d}
\Bigl(
- ({\delta^c}_u {F^d}_v + {\delta^d}_v {F^c}_u ) {F^a}_s {F^b}_t
- ({\delta^a}_s {F^b}_t + {\delta^b}_t {F^a}_s ) {F^c}_u {F^d}_v
\Bigr) \\
\lambda^2 &:
\inv{24} \epsilon^{s t u v} \epsilon_{a b c d}
\Bigl(
{\delta^c}_u {\delta^d}_v {F^a}_s {F^b}_t
+( {\delta^a}_s {F^b}_t + {\delta^b}_t {F^a}_s ) ( {\delta^c}_u {F^d}_v + {\delta^d}_v {F^c}_u )
+ {\delta^a}_s {\delta^b}_t  {F^c}_u {F^d}_v
\Bigr) \\
\lambda^3 &:
\inv{24} \epsilon^{s t u v} \epsilon_{a b c d}
\Bigl(
- ( {\delta^a}_s {F^b}_t + {\delta^b}_t {F^a}_s ) {\delta^c}_u {\delta^d}_v
- {\delta^a}_s {\delta^b}_t  ( {\delta^c}_u {F^d}_v + {\delta^d}_v {F^c}_u )
\Bigr) \\
\lambda^4 &:
\inv{24} \epsilon^{s t u v} \epsilon_{a b c d}
\Bigl(
{\delta^a}_s {\delta^b}_t {\delta^c}_u {\delta^d}_v
\Bigr) \\
\end{aligned}
\end{equation}

By \eqnref{eqn:relElectroDynProblemSet3:660} the \(\lambda^0\) coefficient is just \(\Det \Norm{F_{i j}}\).

The \(\lambda^3\) terms can be seen to be zero.  For example, the first one is

\begin{equation}\label{eqn:relElectroDynProblemSet3:2400}
\begin{aligned}
-\inv{24} \epsilon^{s t u v} \epsilon_{a b c d} {\delta^a}_s {F^b}_t {\delta^c}_u {\delta^d}_v
&=
-\inv{24} \epsilon^{s t u v} \epsilon_{s b u v} {F^b}_t \\
&=
-\inv{12} \delta^{t}_b {F^b}_t \\
&=
-\inv{12} {F^b}_b \\
&=
-\inv{12} F^{bu} g_{ub} \\
&= 0,
\end{aligned}
\end{equation}

where the final equality to zero comes from summing a symmetric and antisymmetric product.

Similarly the \(\lambda\) coefficients can be shown to be zero.  Again the first as a sample is

\begin{equation}\label{eqn:relElectroDynProblemSet3:2420}
\begin{aligned}
-\inv{24} \epsilon^{s t u v} \epsilon_{a b c d} {\delta^c}_u {F^d}_v {F^a}_s {F^b}_t
&=
-\inv{24} \epsilon^{u s t v} \epsilon_{u a b d} {F^d}_v {F^a}_s {F^b}_t  \\
&=
-\inv{24}
\delta^{[s}_a
\delta^{t}_b
\delta^{v]}_d
{F^d}_v {F^a}_s {F^b}_t  \\
&=
-\inv{24}
{F^a}_{[s}
{F^b}_{t}
{F^d}_{v]}
 \\
\end{aligned}
\end{equation}

Disregarding the \(-1/24\) factor, let us just expand this antisymmetric sum

\begin{equation}\label{eqn:relElectroDynProblemSet3:2440}
\begin{aligned}
{F^a}_{[a}
{F^b}_{b}
{F^d}_{d]}
&=
{F^a}_{a}
{F^b}_{b}
{F^d}_{d}
+
{F^a}_{d}
{F^b}_{a}
{F^d}_{b}
+
{F^a}_{b}
{F^b}_{d}
{F^d}_{a} \\
&\qquad -
{F^a}_{a}
{F^b}_{d}
{F^d}_{b}
-
{F^a}_{d}
{F^b}_{b}
{F^d}_{a}
-
{F^a}_{b}
{F^b}_{a}
{F^d}_{d} \\
&=
{F^a}_{d}
{F^b}_{a}
{F^d}_{b}
+
{F^a}_{b}
{F^b}_{d}
{F^d}_{a} \\
\end{aligned}
\end{equation}

Of the two terms above that were retained, they are the only ones without a zero \({F^i}_i\) factor.  Consider the first part of this remaining part of the sum.  Employing the metric tensor, to raise indices so that the antisymmetry of \(F^{ij}\) can be utilized, and then finally relabeling all the dummy indices we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:2460}
\begin{aligned}
{F^a}_{d}
{F^b}_{a}
{F^d}_{b}
&=
F^{a u}
F^{b v}
F^{d w}
g_{d u}
g_{a v}
g_{b w} \\
&=
(-1)^3
F^{u a}
F^{v b}
F^{w d}
g_{d u}
g_{a v}
g_{b w} \\
&=
-
(F^{u a}
g_{a v})
(F^{v b}
g_{b w}
)
(F^{w d}
g_{d u})
\\
&=
-
{F^u}_v
{F^v}_w
{F^w}_u
\\
&=
-
{F^a}_b
{F^b}_d
{F^d}_a
\\
\end{aligned}
\end{equation}

This is just the negative of the second term in the sum, leaving us with zero.

Finally, we have for the \(\lambda^2\) coefficient (\(\times 24\))

\begin{equation}\label{eqn:relElectroDynProblemSet3:2480}
\begin{aligned}
&
\epsilon^{s t u v} \epsilon_{a b c d}
\Bigl(
{\delta^c}_u {\delta^d}_v {F^a}_s {F^b}_t
+{\delta^a}_s {F^b}_t {\delta^c}_u {F^d}_v
+{\delta^b}_t {F^a}_s {\delta^d}_v {F^c}_u  \\
&\qquad +{\delta^b}_t {F^a}_s {\delta^c}_u {F^d}_v
+{\delta^a}_s {F^b}_t {\delta^d}_v {F^c}_u
+ {\delta^a}_s {\delta^b}_t  {F^c}_u {F^d}_v
\Bigr) \\
&=
\epsilon^{s t u v} \epsilon_{a b u v}   {F^a}_s {F^b}_t
+
\epsilon^{s t u v} \epsilon_{s b u d}  {F^b}_t  {F^d}_v
+
\epsilon^{s t u v} \epsilon_{a t c v}  {F^a}_s  {F^c}_u  \\
&\qquad +
\epsilon^{s t u v} \epsilon_{a t u d}  {F^a}_s  {F^d}_v
+
\epsilon^{s t u v} \epsilon_{s b c v}  {F^b}_t  {F^c}_u
+
\epsilon^{s t u v} \epsilon_{s t c d}    {F^c}_u {F^d}_v \\
&=
\epsilon^{s t u v} \epsilon_{a b u v}   {F^a}_s {F^b}_t
+
\epsilon^{t v s u } \epsilon_{b d s u}  {F^b}_t  {F^d}_v
+
\epsilon^{s u t v} \epsilon_{a c t v}  {F^a}_s  {F^c}_u  \\
&\qquad +
\epsilon^{s v t u} \epsilon_{a d t u}  {F^a}_s  {F^d}_v
+
\epsilon^{t u s v} \epsilon_{b c s v}  {F^b}_t  {F^c}_u
+
\epsilon^{u v s t} \epsilon_{c d s t}    {F^c}_u {F^d}_v \\
&=
6
\epsilon^{s t u v} \epsilon_{a b u v} {F^a}_s {F^b}_t  \\
&=
6 (2)
{\delta^{[s}}_a
{\delta^{t]}}_b
{F^a}_s {F^b}_t  \\
&=
12
{F^a}_{[a} {F^b}_{b]}  \\
&=
12( {F^a}_{a} {F^b}_{b} - {F^a}_{b} {F^b}_{a} ) \\
&=
-12 {F^a}_{b} {F^b}_{a} \\
&=
-12 F^{a b} F_{b a} \\
&=
12 F^{a b} F_{a b}
\end{aligned}
\end{equation}

Therefore, our characteristic polynomial is
\boxedEquation{eqn:relElectroDynProblemSet3:980}{
P(\lambda) = \Det \Norm{F_{i j}} + \frac{\lambda^2}{2} F^{a b} F_{a b} + \lambda^4.
}

Observe that in matrix form our strength tensors are

\begin{equation}\label{eqn:relElectroDynProblemSet3:1000}
\begin{aligned}
\Norm{ F^{ij} } &=
\begin{bmatrix}
0 & -E_x & -E_y & -E_z \\
E_x & 0 & -B_z & B_y \\
E_y & B_z & 0 & -B_x \\
E_z & -B_y & B_x & 0
\end{bmatrix} \\
\Norm{ F_{ij} } &=
\begin{bmatrix}
0 & E_x & E_y & E_z \\
-E_x & 0 & -B_z & B_y \\
-E_y & B_z & 0 & -B_x \\
-E_z & -B_y & B_x & 0
\end{bmatrix}.
\end{aligned}
\end{equation}

From these we can compute \(F^{a b} F_{a b}\) easily by inspection

\begin{equation}\label{eqn:relElectroDynProblemSet3:1020}
F^{a b} F_{a b} = 2 (\BB^2 - \BE^2).
\end{equation}

Computing the determinant is not so easy.  The dumb and simple way of expanding by cofactors takes two pages, and yields eventually

\begin{equation}\label{eqn:relElectroDynProblemSet3:1040}
\Det \Norm{ F^{i j} } = (\BE \cdot \BB)^2.
\end{equation}

That supplies us with a relation for the characteristic polynomial in \(\BE\) and \(\BB\)

\boxedEquation{eqn:relElectroDynProblemSet3:980b}{
P(\lambda) = (\BE \cdot \BB)^2 + \lambda^2 (\BB^2 - \BE^2) + \lambda^4.
}

Observe that we found this for the special case where \(\BE\) and \(\BB\) were perpendicular in homework 2.  Observe that when we have that perpendicularity, we can solve for the eigenvalues by inspection

\begin{equation}\label{eqn:relElectroDynProblemSet3:1060}
\lambda \in \{ 0, 0, \pm \sqrt{ \BE^2 - \BB^2 } \},
\end{equation}

and were able to diagonalize the matrix \({F^{i}}_j\) to solve the Lorentz force equation in parametric form.  When \(\Abs{\BE} > \Abs{\BB}\) we had real eigenvalues and an orthogonal diagonalization when \(\BB = 0\).  For the \(\Abs{\BB} > \Abs{\BE}\), we had a two purely imaginary eigenvalues, and when \(\BE = 0\) this was a Hermitian diagonalization.  For the general case, when one of \(\BE\), or \(\BB\) was zero, things did not have the same nice closed form solution.

In general our eigenvalues are

\begin{equation}\label{eqn:relElectroDynProblemSet3:1080}
\lambda = \pm \inv{\sqrt{2}} \sqrt{ \BE^2 - \BB^2 \pm \sqrt{ (\BE^2 - \BB^2)^2 - 4 (\BE \cdot \BB)^2 }}.
\end{equation}

For the purposes of this problem we really only wish to show that \(\BE \cdot \BB\) and \(\BE^2 - \BB^2\) are Lorentz invariants.  When \(\lambda = 0\) we have \(P(\lambda) = (\BE \cdot \BB)^2\), a Lorentz invariant.  This must mean that \(\BE \cdot \BB\) is itself a Lorentz invariant.  Since that is invariant, and we require \(P(\lambda)\) to be invariant for any other possible values of \(\lambda\), the difference \(\BE^2 - \BB^2\) must also be Lorentz invariant.


\makeSubAnswer{}{pr:relElectroDynProblemSet3:1g}

This proceeds in a fairly straightforward fashion

\begin{equation}\label{eqn:relElectroDynProblemSet3:2500}
\begin{aligned}
\int d^4 x \epsilon^{i j k l} F_{ i j } F_{ k l }
&=
\int d^4 x \epsilon^{i j k l} (\partial_i A_j - \partial_j A_i) F_{ k l } \\
&=
\int d^4 x
\epsilon^{i j k l} (\partial_i A_j) F_{ k l }
-\epsilon^{j i k l} (\partial_i A_j) F_{ k l } \\
&=
2 \int d^4 x
\epsilon^{i j k l} (\partial_i A_j) F_{ k l } \\
&=
2 \int d^4 x
\epsilon^{i j k l} \left(
\PD{x^i}{}(A_j F_{ k l }
-A_j \PD{x^i}{ F_{ k l } }
\right)
\\
\end{aligned}
\end{equation}

Now, observe that by the Bianchi identity, this second term is zero

\begin{equation}\label{eqn:relElectroDynProblemSet3:1100}
\epsilon^{i j k l} \PD{x^i}{ F_{ k l } }
=
-\epsilon^{j i k l} \partial_i F_{ k l } = 0
\end{equation}

Now we have a set of perfect differentials, and can integrate

\begin{equation}\label{eqn:relElectroDynProblemSet3:2520}
\begin{aligned}
\int d^4 x \epsilon^{i j k l} F_{ i j } F_{ k l }
&=
2 \int d^4 x
\epsilon^{i j k l}
\PD{x^i}{}(A_j F_{ k l })
\\
&=
2 \int dx^j dx^k dx^l
\epsilon^{i j k l}
\evalbar{(A_j F_{ k l })}{\Delta x^i}
\\
\end{aligned}
\end{equation}

We are left with a only contributions to the integral from the boundary terms on the spacetime hypervolume, three-volume normals bounding the four-volume integration  in the original integral.

\makeSubAnswer{}{pr:relElectroDynProblemSet3:1h}

Let us first consider the explanation of the name.  First recall what the expansions are of \(F_{i j}\) and \(F^{i j}\) in terms of \(\BE\) and \(\BE\).  These are

\begin{equation}\label{eqn:relElectroDynProblemSet3:2540}
\begin{aligned}
F_{0 \alpha}
&= \partial_0 A_\alpha - \partial_\alpha A_0 \\
&= -\inv{c} \PD{t}{A^\alpha} - \PD{x^\alpha}{\phi} \\
&= E_\alpha
\end{aligned}
\end{equation}

with \(F^{0 \alpha} = -E^\alpha\), and \(E^\alpha = E_\alpha\).

The magnetic field components are

\begin{equation}\label{eqn:relElectroDynProblemSet3:2560}
\begin{aligned}
F_{\beta \alpha}
&= \partial_\beta A_\alpha - \partial_\alpha A_\beta \\
&= -\partial_\beta A^\alpha + \partial_\alpha A^\beta \\
&= \epsilon_{\alpha \beta \sigma} B^\sigma
\end{aligned}
\end{equation}

with \(F^{\beta \alpha} = \epsilon^{\alpha \beta \sigma} B_\sigma\) and \(B_\sigma = B^\sigma\).

Now let us expand the dual tensors.  These are

\begin{equation}\label{eqn:relElectroDynProblemSet3:2580}
\begin{aligned}
\tilde{F}_{0 \alpha}
&=
\inv{2} \epsilon_{0 \alpha i j} F^{i j} \\
&=
\inv{2} \epsilon_{0 \alpha \beta \sigma} F^{\beta \sigma} \\
&=
\inv{2} \epsilon_{0 \alpha \beta \sigma} \epsilon^{\sigma \beta \mu} B_\mu \\
&=
-\inv{2} \epsilon_{0 \alpha \beta \sigma} \epsilon^{\mu \beta \sigma} B_\mu \\
&=
-\inv{2} (2!) {\delta_\alpha}^\mu B_\mu \\
&=
- B_\alpha \\
\end{aligned}
\end{equation}

and

\begin{equation}\label{eqn:relElectroDynProblemSet3:2600}
\begin{aligned}
\tilde{F}_{\beta \alpha}
&=
\inv{2} \epsilon_{\beta \alpha i j} F^{i j} \\
&=
\inv{2} \left(
\epsilon_{\beta \alpha 0 \sigma} F^{0 \sigma}
+\epsilon_{\beta \alpha \sigma 0} F^{\sigma 0}
\right) \\
&=
\epsilon_{0 \beta \alpha \sigma} (-E^\sigma) \\
&=
\epsilon_{\alpha \beta \sigma} E^\sigma
\end{aligned}
\end{equation}

Summarizing we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:1120}
\begin{aligned}
F_{0 \alpha} &= E^\alpha \\
F^{0 \alpha} &= -E^\alpha \\
F^{\beta \alpha} &= F_{\beta \alpha} = \epsilon_{\alpha \beta \sigma} B^\sigma \\
\tilde{F}_{0 \alpha} &= - B_\alpha \\
\tilde{F}^{0 \alpha} &= B_\alpha \\
\tilde{F}_{\beta \alpha} &= \tilde{F}^{\beta \alpha} = \epsilon_{\alpha \beta \sigma} E^\sigma
\end{aligned}
\end{equation}

Is there a sign error in the \(\tilde{F}_{0 \alpha} = - B_\alpha\) result?  Other than that we have the same sort of structure for the tensor with \(E\) and \(B\) switched around.

Let us write these in matrix form, to compare

\begin{equation}\label{eqn:relElectroDynProblemSet3:1140}
\begin{array}{l l l l}
\Norm{ \tilde{F}_{i j} } &=
\begin{bmatrix}
0 & -B_x & -B_y & -B_z \\
B_x & 0 & -E_z & E_y \\
B_y & E_z & 0 & E_x \\
B_z & -E_y & -E_x & 0 \\
\end{bmatrix}
& \Norm{ \tilde{F}^{i j} } &=
\begin{bmatrix}
0 & B_x & B_y & B_z \\
-B_x & 0 & -E_z & E_y \\
-B_y & E_z & 0 & -E_x \\
-B_z & -E_y & E_x & 0 \\
\end{bmatrix} \\
\Norm{ F^{ij} } &=
\begin{bmatrix}
0 & -E_x & -E_y & -E_z \\
E_x & 0 & -B_z & B_y \\
E_y & B_z & 0 & -B_x \\
E_z & -B_y & B_x & 0
\end{bmatrix}
& \Norm{ F_{ij} } &=
\begin{bmatrix}
0 & E_x & E_y & E_z \\
-E_x & 0 & -B_z & B_y \\
-E_y & B_z & 0 & -B_x \\
-E_z & -B_y & B_x & 0
\end{bmatrix}.
\end{array}
\end{equation}

From these we can see by inspection that we have
\begin{equation}\label{eqn:relElectroDynProblemSet3:1160}
\tilde{F}^{i j} F_{ij} = \tilde{F}_{i j} F^{ij} = 4 (\BE \cdot \BB)
\end{equation}

This is consistent with the stated result in \citep{wiki:electromagneticTensor} (except for a factor of \(c\) due to units differences), so it appears the signs above are all kosher.

Now, let us see if the if the dual tensor satisfies the vacuum equations.

\begin{equation}\label{eqn:relElectroDynProblemSet3:2620}
\begin{aligned}
\partial_j \tilde{F}^{i j}
&=
\partial_j \inv{2} \epsilon^{i j k l} F_{k l} \\
&=
\inv{2} \epsilon^{i j k l} \partial_j (\partial_k A_l - \partial_l A_k) \\
&=
\inv{2} \epsilon^{i j k l} \partial_j \partial_k A_l - \inv{2} \epsilon^{i j l k} \partial_k A_l \\
&=
\inv{2} (\epsilon^{i j k l} - \epsilon^{i j k l} \partial_k A_l \\
&= 0. \qedmarker
\end{aligned}
\end{equation}

So the first checks out, provided we have no sources.  If we have sources, then we see here that Maxwell's equations do not hold since this would imply that the four current density must be zero.

How about the Bianchi identity?  That gives us

\begin{equation}\label{eqn:relElectroDynProblemSet3:2640}
\begin{aligned}
\epsilon^{i j k l} \partial_j \tilde{F}_{k l}
&=
\epsilon^{i j k l} \partial_j \inv{2} \epsilon_{k l a b} F^{a b} \\
&=
\inv{2} \epsilon^{k l i j} \epsilon_{k l a b} \partial_j F^{a b} \\
&=
\inv{2} (2!) {\delta^i}_{[a} {\delta^j}_{b]} \partial_j F^{a b} \\
&=
\partial_j (F^{i j} - F^{j i} ) \\
&=
2 \partial_j F^{i j} .
\end{aligned}
\end{equation}

The factor of two is slightly curious.  Is there a mistake above?  If there is a mistake, it does not change the fact that Maxwell's equation

\begin{equation}\label{eqn:relElectroDynProblemSet3:1200}
\partial_k F^{k i} = \frac{4 \pi}{c} j^i
\end{equation}

Gives us zero for the Bianchi identity under source free conditions of \(j^i = 0\).
}
